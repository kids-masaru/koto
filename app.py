"""
Koto AI Secretary - LINE Bot Entry Point
Flask server with asynchronous message processing and Config API
"""
import os
import sys
import json
import hashlib
import hmac
import base64
import urllib.request
import threading
from flask import Flask, request
from dotenv import load_dotenv

load_dotenv()

# Add project root to path for imports
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from core.agent import get_gemini_response
from utils.storage import clear_user_history
from utils.sheets_config import load_config, save_config
from tools.google_ops import search_drive
from flask_cors import CORS

app = Flask(__name__)
# Enable CORS for dashboard - allow all origins and handle preflight
CORS(app, resources={r"/api/*": {"origins": "*", "methods": ["GET", "POST", "OPTIONS"], "allow_headers": ["Content-Type"]}})


@app.route('/')
def healthcheck():
    """Health check endpoint for Railway/deployment platforms"""
    return 'KOTO is running!', 200


@app.route('/debug/vector-status')
def vector_status():
    """Debug endpoint to check vector store status"""
    import json
    try:
        from utils.vector_store import get_collection_stats
        stats = get_collection_stats()
        return json.dumps(stats, ensure_ascii=False), 200, {'Content-Type': 'application/json'}
    except Exception as e:
        return json.dumps({"error": str(e)}), 500, {'Content-Type': 'application/json'}


# LINE credentials
LINE_CHANNEL_SECRET = os.environ.get('LINE_CHANNEL_SECRET', '')
LINE_CHANNEL_ACCESS_TOKEN = os.environ.get('LINE_CHANNEL_ACCESS_TOKEN', '')


def verify_signature(body, signature):
    """Verify LINE webhook signature"""
    if not LINE_CHANNEL_SECRET:
        return True
    hash_value = hmac.new(
        LINE_CHANNEL_SECRET.encode('utf-8'),
        body.encode('utf-8'),
        hashlib.sha256
    ).digest()
    return hmac.compare_digest(signature, base64.b64encode(hash_value).decode('utf-8'))


def push_message(user_id, texts):
    """Send message via LINE Push API (for async responses)
       texts: string or list of strings
    """
    url = 'https://api.line.me/v2/bot/message/push'
    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {LINE_CHANNEL_ACCESS_TOKEN}'
    }
    
    # Normalize to list
    if isinstance(texts, str):
        texts = [texts]
        
    messages = []
    for text in texts:
        # Truncate if too long
        if len(text) > 4500:
            text = text[:4500] + "..."
        messages.append({'type': 'text', 'text': text})
    
    # Send in chunks of 5 (LINE API limit)
    for i in range(0, len(messages), 5):
        chunk = messages[i:i+5]
        
        data = {
            'to': user_id,
            'messages': chunk
        }
        
        req = urllib.request.Request(
            url,
            data=json.dumps(data).encode('utf-8'),
            headers=headers,
            method='POST'
        )
        
        try:
            with urllib.request.urlopen(req) as res:
                print(f"Push sent to {user_id[:8]}: {res.status}", file=sys.stderr)
        except Exception as e:
            print(f"Push error: {e}", file=sys.stderr)


def reply_message(reply_token, text):
    """Send message via LINE Reply API (for sync responses)"""
    url = 'https://api.line.me/v2/bot/message/reply'
    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {LINE_CHANNEL_ACCESS_TOKEN}'
    }
    
    if len(text) > 4500:
        text = text[:4500] + "..."
    
    data = {
        'replyToken': reply_token,
        'messages': [{'type': 'text', 'text': text}]
    }
    
    req = urllib.request.Request(
        url,
        data=json.dumps(data).encode('utf-8'),
        headers=headers,
        method='POST'
    )
    
    try:
        with urllib.request.urlopen(req) as res:
            print(f"Reply sent: {res.status}", file=sys.stderr)
    except Exception as e:
        print(f"Reply error: {e}", file=sys.stderr)


def get_line_message_content(message_id):
    """Download message content (image/file) from LINE"""
    # Note: Use api-data.line.me for content
    url = f'https://api-data.line.me/v2/bot/message/{message_id}/content'
    headers = {
        'Authorization': f'Bearer {LINE_CHANNEL_ACCESS_TOKEN}'
    }
    
    req = urllib.request.Request(url, headers=headers)
    try:
        with urllib.request.urlopen(req) as res:
            return res.read()
    except Exception as e:
        print(f"Content download error: {e}", file=sys.stderr)
        return None


def process_message_async(user_id, user_text, reply_token=None, message_id=None, message_type='text', filename=None):
    """Process message (text or file) in background"""
    try:
        print(f"Processing {message_type} from {user_id[:8]}", file=sys.stderr)
        
        # Handle File Uploads
        if message_type in ['image', 'file']:
            reply_token_used = False
            
            # 1. Download from LINE
            content = get_line_message_content(message_id)
            if not content:
                if reply_token:
                    reply_message(reply_token, "ã”ã‚ã‚“ãªã•ã„ã€ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ...ğŸ˜¢")
                return

            # 2. Determine filename
            if not filename:
                import datetime
                ext = 'jpg' if message_type == 'image' else 'dat'
                timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
                filename = f"line_{timestamp}.{ext}"

            # 3. Upload to Drive
            from tools.google_ops import upload_file_to_drive
            mime = 'image/jpeg' if message_type == 'image' else None # Auto-detect for others
            
            result = upload_file_to_drive(filename, content, mime_type=mime)
            
            if result.get("success"):
                file_url = result.get("url")
                # User didn't say anything, but the act of uploading is the message.
                # format as a system notification to the agent
                user_text = f"ã€ã‚·ã‚¹ãƒ†ãƒ é€šçŸ¥ã€‘ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚\nãƒ•ã‚¡ã‚¤ãƒ«å: {filename}\nä¿å­˜å…ˆURL: {file_url}\n(ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã«ã¤ã„ã¦èã‹ã‚ŒãŸã‚‰ Maker Agent ç­‰ã‚’ä½¿ã£ã¦ãã ã•ã„)"
                
                # Notify user immediately (Optional, but good UX)
                # But we want KOTO to reply naturally, so maybe let KOTO generate the reply.
                # However, KOTO might take time. Let's rely on KOTO.
            else:
                error = result.get("error", "Unknown error")
                if reply_token:
                    reply_message(reply_token, f"ãƒ‰ãƒ©ã‚¤ãƒ–ã¸ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ...ğŸ˜¢\n{error}")
                return

        # Normal Agent Flow (Text or converted System Text)
        print(f"Agent Input: {user_text}", file=sys.stderr)
        ai_response = get_gemini_response(user_id, user_text)
        
        print(f"Koto response: {ai_response[:100]}...", file=sys.stderr)
        
        # Try Reply API first
        success = False
        if reply_token:
            try:
                reply_message(reply_token, ai_response)
                success = True
            except Exception as e:
                 # Token might have expired during upload/processing
                print(f"Reply failed, trying Push: {e}", file=sys.stderr)
        
        # Fallback to Push
        if not success:
            push_message(user_id, ai_response)
            
    except Exception as e:
        print(f"Async processing error: {e}", file=sys.stderr)
        try:
            push_message(user_id, "ã”ã‚ã‚“ãªã•ã„ã€ã‚¨ãƒ©ãƒ¼ãŒå‡ºã¡ã‚ƒã„ã¾ã—ãŸ...ğŸ˜¢")
        except:
            pass



@app.route('/', methods=['GET'])
def health_check():
    """Health check endpoint"""
    return 'Koto AI Secretary is running!', 200


@app.route('/webhook', methods=['POST'])
def webhook():
    """LINE webhook endpoint - returns immediately, processes async"""
    signature = request.headers.get('X-Line-Signature', '')
    body = request.get_data(as_text=True)
    
    if not verify_signature(body, signature):
        return 'Invalid signature', 400
    
    try:
        data = json.loads(body)
        events = data.get('events', [])
    except Exception:
        return 'OK', 200
    
    for event in events:
        event_type = event.get('type')
        source = event.get('source', {})
        user_id = source.get('userId', 'unknown')
        
        if event_type == 'message':
            message = event.get('message', {})
            message_type = message.get('type')
            
            reply_token = event.get('replyToken')
            
            if message_type == 'text':
                user_text = message.get('text', '')
                print(f"User Text [{user_id[:8]}]: {user_text}", file=sys.stderr)
                process_message_async(user_id, user_text, reply_token)
                
            elif message_type == 'image':
                message_id = message.get('id')
                print(f"User Image [{user_id[:8]}] ID: {message_id}", file=sys.stderr)
                process_message_async(user_id, "", reply_token, message_id=message_id, message_type='image')
                
            elif message_type == 'file':
                message_id = message.get('id')
                filename = message.get('fileName')
                print(f"User File [{user_id[:8]}] Name: {filename}", file=sys.stderr)
                process_message_async(user_id, "", reply_token, message_id=message_id, message_type='file', filename=filename)
        
        elif event_type == 'follow':
            reply_token = event.get('replyToken')
            clear_user_history(user_id)
            if reply_token:
                reply_message(
                    reply_token,
                    "ã‚ã€ã“ã‚“ã«ã¡ã¯ï¼ã‚³ãƒˆã§ã™ğŸ˜Š\n\n"
                    "è‰²ã€…ãŠæ‰‹ä¼ã„ã§ãã¾ã™ã‚ˆã€œï¼\n"
                    "ãƒ»ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæˆ\n"
                    "ãƒ»ãƒ¡ãƒ¼ãƒ«ç¢ºèª\n"
                    "ãƒ»è¨ˆç®—\n"
                    "ãƒ»PDFèª­ã¿å–ã‚Š\n"
                    "ãƒ»Webæ¤œç´¢\n\n"
                    "æ°—è»½ã«è¨€ã£ã¦ãã ã•ã„ã­ï¼"
                )
    
    # Return immediately - processing happens in background
    return 'OK', 200

# Initialize Scheduler
from apscheduler.schedulers.background import BackgroundScheduler
import atexit

def check_reminders():
    """Scheduled job to check and send reminders"""
    # Use existing cron logic but internalize the context
    with app.app_context():
        try:
            # Reusing the logic from the old route, but suited for internal execution
            from utils.user_db import get_active_users
            users = get_active_users()
            print(f"Scheduler: Checking reminders for {len(users)} users...", file=sys.stderr)
            
            for user in users:
                process_user_reminders(user)
                
        except Exception as e:
            print(f"Scheduler Error: {e}", file=sys.stderr)

def process_user_reminders(user):
    """Process reminders for a single user"""
    user_id = user['user_id']
    location = user['location']
    
    auth_config = load_config() # Ideally load user-specific config
    reminders = auth_config.get('reminders', [])
    
    # Fallback for old format
    if not reminders and auth_config.get('reminder_time'):
         reminders = [{
            'name': 'æœã®ãƒªãƒã‚¤ãƒ³ãƒ€ãƒ¼',
            'time': auth_config.get('reminder_time', '07:00'),
            'prompt': auth_config.get('reminder_prompt', 'ä»Šæ—¥ã®å¤©æ°—ã¨äºˆå®šã‚’æ•™ãˆã¦'),
            'enabled': True
        }]

    from datetime import datetime, timezone, timedelta
    jst = timezone(timedelta(hours=9))
    now = datetime.now(jst)
    current_hour = now.hour
    current_minute = now.minute
    
    for reminder in reminders:
        if not reminder.get('enabled', True): continue
        
        # Simple hour checks for now (can enhance to minute level)
        r_time = reminder.get('time', '07:00')
        try:
            r_hour = int(r_time.split(':')[0])
        except:
            r_hour = 7
            
        if r_hour != current_hour: continue
        
        # Prevent double sending if checked multiple times in same hour?
        # For now, scheduler runs hourly so it should be fine.
        
        send_reminder(user_id, location, reminder)

def send_reminder(user_id, location, reminder):
    prompt = (
        f"ä»Šæ—¥ã®{location}ã®{reminder.get('prompt')}\n"
        "ã€é‡è¦ã€‘ä»¥ä¸‹ã®3ã¤ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«åˆ†ã‘ã¦ã€ãã‚Œãã‚Œã®é–“ã«ã€Œ@@@ã€ã¨ã„ã†åŒºåˆ‡ã‚Šæ–‡å­—ã‚’å…¥ã‚Œã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚\n"
        "1. å¤©æ°—ã«é–¢ã™ã‚‹æƒ…å ±\n"
        "2. ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ»ã‚¿ã‚¹ã‚¯ã«é–¢ã™ã‚‹æƒ…å ±\n"
        "3. æ°—ã®åˆ©ã„ãŸä¸€è¨€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸"
    )
    
    try:
        response = get_gemini_response(user_id, prompt)
        messages = [msg.strip() for msg in response.split('@@@') if msg.strip()]
        
        # Add greeting
        from datetime import datetime, timezone, timedelta
        jst = timezone(timedelta(hours=9))
        h = datetime.now(jst).hour
        if messages:
            if h < 12 and "ãŠã¯ã‚ˆã†" not in messages[0]:
                messages[0] = f"ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™ï¼â˜€ï¸\n\n{messages[0]}"
            elif h >= 18 and "ã“ã‚“ã°ã‚“ã¯" not in messages[0]:
                messages[0] = f"ã“ã‚“ã°ã‚“ã¯ï¼ğŸŒ™\n\n{messages[0]}"
        else:
            messages = [response]
            
        push_message(user_id, messages)
        print(f"Sent reminder to {user_id[:8]}", file=sys.stderr)
    except Exception as e:
        print(f"Failed to send reminder: {e}", file=sys.stderr)


# Start Scheduler
scheduler = BackgroundScheduler()
scheduler.add_job(func=check_reminders, trigger="cron", hour="*", minute=0) # Run every hour on the hour

# Profiler Job (Run daily at 3 AM JST = 18:00 UTC)
def run_profiler():
    """Run profiler for all active users"""
    with app.app_context():
        try:
            from core.profiler import profiler
            from utils.user_db import get_active_users
            
            users = get_active_users()
            print(f"Profiler: Starting daily analysis for {len(users)} users...", file=sys.stderr)
            
            for user in users:
                user_id = user['user_id']
                # Run profile analysis
                profiler.run_analysis(user_id)
                
        except Exception as e:
            print(f"Profiler Job Error: {e}", file=sys.stderr)

scheduler.add_job(func=run_profiler, trigger="cron", hour=18) # 18:00 UTC = 03:00 JST

scheduler.start()
atexit.register(lambda: scheduler.shutdown())


@app.route('/cron', methods=['GET'])
def cron_job():
    """Manual trigger for reminders (Legacy/Debug)"""
    check_reminders()
    return 'Reminders checked manually', 200

@app.route('/debug/run-profiler', methods=['POST'])
def debug_run_profiler():
    """Manual trigger for profiler"""
    run_profiler()
    return 'Profiler triggered', 200


@app.route('/api/config', methods=['GET', 'POST', 'OPTIONS'])
def handle_config():
    """Get or update configuration"""
    # Handle preflight request
    if request.method == 'OPTIONS':
        response = app.make_default_options_response()
        response.headers['Access-Control-Allow-Origin'] = '*'
        response.headers['Access-Control-Allow-Methods'] = 'GET, POST, OPTIONS'
        response.headers['Access-Control-Allow-Headers'] = 'Content-Type'
        return response
    
    if request.method == 'GET':
        return json.dumps(load_config(), ensure_ascii=False), 200, {'Content-Type': 'application/json'}
    
    elif request.method == 'POST':
        try:
            new_config = request.json
            if save_config(new_config):
                return json.dumps({"success": True, "config": new_config}), 200, {'Content-Type': 'application/json'}
            else:
                return json.dumps({"error": "Failed to save config"}), 500, {'Content-Type': 'application/json'}
        except Exception as e:
            return json.dumps({"error": str(e)}), 400, {'Content-Type': 'application/json'}

@app.route('/api/profile', methods=['GET', 'POST', 'OPTIONS'])
def handle_profile():
    """Get or update User Profile (Psychological Data)"""
    # Handle preflight request
    if request.method == 'OPTIONS':
        response = app.make_default_options_response()
        response.headers['Access-Control-Allow-Origin'] = '*'
        response.headers['Access-Control-Allow-Methods'] = 'GET, POST, OPTIONS'
        response.headers['Access-Control-Allow-Headers'] = 'Content-Type'
        return response
    
    # Authenticate via config (simplified for single-user context)
    # Ideally should get user_id from token, but we are using LINE user ID.
    # We'll fetch the FIRST active user from user_db for dashboard purposes.
    from utils.user_db import get_active_users
    from utils.vector_store import get_user_profile, save_user_profile
    
    users = get_active_users()
    if not users:
        return json.dumps({"error": "No active users found"}), 404, {'Content-Type': 'application/json'}
    
    # Default to the first user found (Single user mode assumption)
    target_user_id = request.args.get('user_id', users[0]['user_id'])
    
    if request.method == 'GET':
        profile = get_user_profile(target_user_id)
        return json.dumps(profile, ensure_ascii=False), 200, {'Content-Type': 'application/json'}
        
    elif request.method == 'POST':
        try:
            new_profile = request.json
            if save_user_profile(target_user_id, new_profile):
                return json.dumps({"success": True, "profile": new_profile}), 200, {'Content-Type': 'application/json'}
            else:
                return json.dumps({"error": "Failed to save profile"}), 500, {'Content-Type': 'application/json'}
        except Exception as e:
            return json.dumps({"error": str(e)}), 400, {'Content-Type': 'application/json'}

@app.route('/api/folders', methods=['GET', 'OPTIONS'])
def list_folders():
    """List Google Drive folders for selection (Navigation support)"""
    # Handle preflight request
    if request.method == 'OPTIONS':
        response = app.make_default_options_response()
        response.headers['Access-Control-Allow-Origin'] = '*'
        response.headers['Access-Control-Allow-Methods'] = 'GET, OPTIONS'
        response.headers['Access-Control-Allow-Headers'] = 'Content-Type'
        return response
    
    query = request.args.get('q', '')
    parent_id = request.args.get('parentId')
    
    try:
        from utils.auth import get_google_credentials
        from googleapiclient.discovery import build
        
        creds = get_google_credentials()
        if not creds:
             return json.dumps({"error": "Auth failed"}), 401, {'Content-Type': 'application/json'}
             
        service = build('drive', 'v3', credentials=creds)
        
        # Base filter: folders only, not trashed
        q_filter = "mimeType = 'application/vnd.google-apps.folder' and trashed = false"
        
        if parent_id:
            # Navigate into specific folder
            q_filter += f" and '{parent_id}' in parents"
        elif query:
            # Search mode (global)
            # Escape single quotes
            safe_query = query.replace("'", "\\'")
            q_filter += f" and name contains '{safe_query}'"
        else:
            # Default: Root folder
            q_filter += " and 'root' in parents"
            
        results = service.files().list(
            q=q_filter,
            pageSize=50,
            fields="files(id, name)",
            orderBy="folder,name",
            includeItemsFromAllDrives=True,
            supportsAllDrives=True
        ).execute()
        
        folders = results.get('files', [])
        return json.dumps({"folders": folders}), 200, {'Content-Type': 'application/json'}
        
    except Exception as e:
        return json.dumps({"error": str(e)}), 500, {'Content-Type': 'application/json'}


if __name__ == '__main__':
    port = int(os.environ.get('PORT', 8080))
    print(f"Starting Koto AI Secretary on port {port}...", file=sys.stderr)
    app.run(host='0.0.0.0', port=port)
